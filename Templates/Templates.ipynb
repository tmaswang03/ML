{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split #for data preprocessing and crass validating \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVC #for SVMs\n",
    "from sklearn.linear_model import LogisticRegression #logistic Regression\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest \n",
    "\n",
    "from statistics import mean\n",
    "from hyperopt import Trials, hp, fmin, tpe, STATUS_OK, space_eval #for hyperparameter tuning and minimizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv()\n",
    "# do one hot encoding\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'mean') #could also use mean, median, most freq\n",
    "df = pd.DataFrame(imp.fit_transform(df), columns = df.columns)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'C' : hp.choice('C', [0.5, 1, 10, 100]),\n",
    "    'gamma' : hp.choice('gamma', [1, 0.1, 0.01, 0.001, 0.0001] + ['scale']),\n",
    "    'kernel' : hp.choice('kernel', ['rbf', 'poly'])\n",
    "} #defines the space in which we do hyperparameter tuning for C, gamma and kernel\n",
    "kfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "\n",
    "def objective(params) : #objective function to minimize for hyperparameter tuning\n",
    "    svc = SVC(**params) #grab all keyword paramaters\n",
    "    # cross_val_score takes in object to fit, x, y shape, cv generator (in this case kfold), \n",
    "    #scoring metric, and number of parallel processings (just do 1 cuz h0m3l355)\n",
    "    scores = cross_val_score(svc, x_train, y_train, cv = kfold, scoring = 'accuracy', n_jobs = -1)\n",
    "    print(params)\n",
    "    best_score = mean(scores) \n",
    "    loss = -best_score\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "    \n",
    "num_trials = Trials()\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 30, trials = num_trials)\n",
    "\n",
    "svc = SVC(C = space_eval(space, best)['C'], gamma = space_eval(space, best)['gamma'], kernel = space_eval(space, best)['kernel'])\n",
    "svc.fit(x_train, y_train)\n",
    "svc.score(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m logistic_regression \u001b[39m=\u001b[39m LogisticRegression(solver \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m, max_iter \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m) \u001b[39m#change solver based on data set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m logic_regression\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      3\u001b[0m logistic_regression\u001b[39m.\u001b[39mscore(x_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(solver = 'liblinear', max_iter = 500) #change solver based on data set\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "logistic_regression.score(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 150)),\n",
    "    'max_depth': hp.choice('max_depth', [1, 5, 10, 20, 50, 75, 100, 150, 200]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 3, 4, 5, 10, 20]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 3, 4, 5]),\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'auto', 'log2'])\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "def objective(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv = kfold, scoring = 'accuracy', n_jobs = -1)\n",
    "    best_score = mean(scores) \n",
    "#     print(params)\n",
    "    loss = -best_score\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "num_trials = Trials()\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 300, trials = num_trials)\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators = space_eval(space, best)['n_estimators'], max_depth = space_eval(space, best)['max_depth'],\n",
    "                                     min_samples_split = space_eval(space, best)['min_samples_split'], min_samples_leaf = space_eval(space, best)['min_samples_leaf'],\n",
    "                                     bootstrap = space_eval(space, best)['bootstrap'], criterion = space_eval(space, best)['criterion'], max_features = space_eval(space, best)['max_features'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
